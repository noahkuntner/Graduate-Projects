{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to turn on GPU accelerator on the right tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-12T10:34:45.754923Z",
     "iopub.status.busy": "2021-11-12T10:34:45.754358Z",
     "iopub.status.idle": "2021-11-12T10:34:45.760046Z",
     "shell.execute_reply": "2021-11-12T10:34:45.758987Z",
     "shell.execute_reply.started": "2021-11-12T10:34:45.754883Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:34:46.083986Z",
     "iopub.status.busy": "2021-11-12T10:34:46.083644Z",
     "iopub.status.idle": "2021-11-12T10:34:46.090665Z",
     "shell.execute_reply": "2021-11-12T10:34:46.089917Z",
     "shell.execute_reply.started": "2021-11-12T10:34:46.083945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 888\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:34:46.675220Z",
     "iopub.status.busy": "2021-11-12T10:34:46.674943Z",
     "iopub.status.idle": "2021-11-12T10:34:47.861115Z",
     "shell.execute_reply": "2021-11-12T10:34:47.860135Z",
     "shell.execute_reply.started": "2021-11-12T10:34:46.675177Z"
    }
   },
   "outputs": [],
   "source": [
    "directory_train = \"../input/cv-assignment-2-224x224-training-set\"\n",
    "\n",
    "pixels = 380\n",
    "batch_size = 64\n",
    "num_class = 75\n",
    "\n",
    "def generate_data_df_with_folds(kfold=10):\n",
    "    files = pd.DataFrame()\n",
    "\n",
    "    tmp = []\n",
    "    labels_1 = []\n",
    "    for i in range(75):\n",
    "        for x,_,z in os.walk(directory_train+'/'+str(i)):\n",
    "            for file in z:\n",
    "                if 'desktop.ini' not in file:\n",
    "                    filepath = x+'/'+file\n",
    "                    tmp.append(filepath)\n",
    "                    labels_1.append(i)\n",
    "\n",
    "    labels_2 = [1 if i in range(15,74) else 0 for i in labels_1] #1 if food, 0 if place\n",
    "    files['filepaths'] = pd.Series(tmp)\n",
    "    files['target'] = pd.Series(labels_1)\n",
    "\n",
    "    folds = []\n",
    "    for i in range(75):\n",
    "        n = files[files['target']==i].shape[0]\n",
    "        tmp = []\n",
    "        for fold in range(kfold):\n",
    "            if fold != kfold-1:\n",
    "                tmp += [fold]*(n//kfold)\n",
    "            else:\n",
    "                tmp+= [fold]*(n-len(tmp))\n",
    "        random.shuffle(tmp)\n",
    "        folds+=tmp\n",
    "    files['fold'] = folds\n",
    "    files['target'] = files['target'].astype(str)\n",
    "    return files\n",
    "\n",
    "files = generate_data_df_with_folds(kfold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:34:47.863316Z",
     "iopub.status.busy": "2021-11-12T10:34:47.862948Z",
     "iopub.status.idle": "2021-11-12T10:34:47.867023Z",
     "shell.execute_reply": "2021-11-12T10:34:47.866265Z",
     "shell.execute_reply.started": "2021-11-12T10:34:47.863282Z"
    }
   },
   "outputs": [],
   "source": [
    "def AHE(img):\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
    "    return img_adapteq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:34:47.868960Z",
     "iopub.status.busy": "2021-11-12T10:34:47.868493Z",
     "iopub.status.idle": "2021-11-12T10:34:47.879469Z",
     "shell.execute_reply": "2021-11-12T10:34:47.878819Z",
     "shell.execute_reply.started": "2021-11-12T10:34:47.868923Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    '''Add random noise to an image'''\n",
    "    VARIABILITY = 50\n",
    "    deviation = VARIABILITY*random.random()\n",
    "    noise = np.random.normal(0, deviation, img.shape)\n",
    "    img += noise\n",
    "    np.clip(img, 0., 255.)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:34:48.283847Z",
     "iopub.status.busy": "2021-11-12T10:34:48.283592Z",
     "iopub.status.idle": "2021-11-12T10:34:48.291487Z",
     "shell.execute_reply": "2021-11-12T10:34:48.290622Z",
     "shell.execute_reply.started": "2021-11-12T10:34:48.283814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing function specific to base model\n",
    "preproc_func_effnet = tf.keras.applications.efficientnet.preprocess_input # pass through layer\n",
    "preproc_func = preproc_func_effnet\n",
    "\n",
    "# Set seed for reproducibility\n",
    "#set_seeds(123)\n",
    "\n",
    "# Create train / valid data generator\n",
    "batch_size = 16\n",
    "num_classes = 75\n",
    "img_size = 380\n",
    "train_dir = os.path.abspath(\"train\")\n",
    "gen = tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip = True,\n",
    "                            vertical_flip=True,\n",
    "                            rotation_range = 10,\n",
    "                            width_shift_range=0.25,\n",
    "                            height_shift_range=0.25,\n",
    "                            zoom_range=0.4,\n",
    "brightness_range=[0.2,1.5],\n",
    "              validation_split=0.1, \n",
    "              fill_mode=\"nearest\",\n",
    "              preprocessing_function=preproc_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:34:49.028312Z",
     "iopub.status.busy": "2021-11-12T10:34:49.027867Z",
     "iopub.status.idle": "2021-11-12T10:35:01.079724Z",
     "shell.execute_reply": "2021-11-12T10:35:01.079021Z",
     "shell.execute_reply.started": "2021-11-12T10:34:49.028273Z"
    }
   },
   "outputs": [],
   "source": [
    "#gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "train_dataset = gen.flow_from_dataframe(files[files['fold']>1],x_col='filepaths',y_col='target',\n",
    "                                class_mode='sparse',batch_size=batch_size,target_size=(224, 224))\n",
    "valid_dataset = gen.flow_from_dataframe(files[files['fold']<=1],x_col='filepaths',y_col='target',\n",
    "                                class_mode='sparse',batch_size=batch_size,target_size=(224, 224),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:06.248054Z",
     "iopub.status.busy": "2021-11-12T10:38:06.247285Z",
     "iopub.status.idle": "2021-11-12T10:38:06.253478Z",
     "shell.execute_reply": "2021-11-12T10:38:06.252477Z",
     "shell.execute_reply.started": "2021-11-12T10:38:06.248018Z"
    }
   },
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 224\n",
    "TARGET_WIDTH = 224\n",
    "BATCH_SIZE = 16\n",
    "VALIDATION_SPLIT= 0.2\n",
    "EPOCHS = 15\n",
    "NORMALIZE = False\n",
    "num_classes = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:06.841444Z",
     "iopub.status.busy": "2021-11-12T10:38:06.840961Z",
     "iopub.status.idle": "2021-11-12T10:38:06.849259Z",
     "shell.execute_reply": "2021-11-12T10:38:06.848438Z",
     "shell.execute_reply.started": "2021-11-12T10:38:06.841410Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.applications import NASNetLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:07.169985Z",
     "iopub.status.busy": "2021-11-12T10:38:07.169425Z",
     "iopub.status.idle": "2021-11-12T10:38:07.192924Z",
     "shell.execute_reply": "2021-11-12T10:38:07.192167Z",
     "shell.execute_reply.started": "2021-11-12T10:38:07.169946Z"
    }
   },
   "outputs": [],
   "source": [
    "class SwinTransformer(layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        num_patch,\n",
    "        num_heads,\n",
    "        window_size=7,\n",
    "        shift_size=0,\n",
    "        num_mlp=1024,\n",
    "        qkv_bias=True,\n",
    "        dropout_rate=0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(SwinTransformer, self).__init__(**kwargs)\n",
    "\n",
    "        self.dim = dim  # number of input dimensions\n",
    "        self.num_patch = num_patch  # number of embedded patches\n",
    "        self.num_heads = num_heads  # number of attention heads\n",
    "        self.window_size = window_size  # size of window\n",
    "        self.shift_size = shift_size  # size of window shift\n",
    "        self.num_mlp = num_mlp  # number of MLP nodes\n",
    "\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
    "        self.attn = WindowAttention(\n",
    "            dim,\n",
    "            window_size=(self.window_size, self.window_size),\n",
    "            num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias,\n",
    "            dropout_rate=dropout_rate,\n",
    "        )\n",
    "        self.drop_path = DropPath(dropout_rate)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
    "\n",
    "        self.mlp = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(num_mlp),\n",
    "                layers.Activation(keras.activations.gelu),\n",
    "                layers.Dropout(dropout_rate),\n",
    "                layers.Dense(dim),\n",
    "                layers.Dropout(dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if min(self.num_patch) < self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.num_patch)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size == 0:\n",
    "            self.attn_mask = None\n",
    "        else:\n",
    "            height, width = self.num_patch\n",
    "            h_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            w_slices = (\n",
    "                slice(0, -self.window_size),\n",
    "                slice(-self.window_size, -self.shift_size),\n",
    "                slice(-self.shift_size, None),\n",
    "            )\n",
    "            mask_array = np.zeros((1, height, width, 1))\n",
    "            count = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    mask_array[:, h, w, :] = count\n",
    "                    count += 1\n",
    "            mask_array = tf.convert_to_tensor(mask_array)\n",
    "\n",
    "            # mask array to windows\n",
    "            mask_windows = window_partition(mask_array, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, shape=[-1, self.window_size * self.window_size]\n",
    "            )\n",
    "            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n",
    "                mask_windows, axis=2\n",
    "            )\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        height, width = self.num_patch\n",
    "        _, num_patches_before, channels = x.shape\n",
    "        x_skip = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape=(-1, height, width, channels))\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n",
    "        )\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n",
    "        )\n",
    "        shifted_x = window_reverse(\n",
    "            attn_windows, self.window_size, height, width, channels\n",
    "        )\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(\n",
    "                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n",
    "            )\n",
    "        else:\n",
    "            x = shifted_x\n",
    "\n",
    "        x = tf.reshape(x, shape=(-1, height * width, channels))\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        x_skip = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = self.drop_path(x)\n",
    "        x = x_skip + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:07.295878Z",
     "iopub.status.busy": "2021-11-12T10:38:07.295560Z",
     "iopub.status.idle": "2021-11-12T10:38:15.148123Z",
     "shell.execute_reply": "2021-11-12T10:38:15.147092Z",
     "shell.execute_reply.started": "2021-11-12T10:38:07.295836Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:15.155416Z",
     "iopub.status.busy": "2021-11-12T10:38:15.153472Z",
     "iopub.status.idle": "2021-11-12T10:38:15.161253Z",
     "shell.execute_reply": "2021-11-12T10:38:15.160241Z",
     "shell.execute_reply.started": "2021-11-12T10:38:15.155372Z"
    }
   },
   "outputs": [],
   "source": [
    "#from .model import SwinTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:15.165790Z",
     "iopub.status.busy": "2021-11-12T10:38:15.164320Z",
     "iopub.status.idle": "2021-11-12T10:38:15.320492Z",
     "shell.execute_reply": "2021-11-12T10:38:15.319792Z",
     "shell.execute_reply.started": "2021-11-12T10:38:15.165549Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, LayerNormalization, GlobalAveragePooling1D\n",
    "\n",
    "CFGS = {\n",
    "    'swin_tiny_224': dict(input_size=(224, 224), window_size=7, embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24]),\n",
    "    'swin_small_224': dict(input_size=(224, 224), window_size=7, embed_dim=96, depths=[2, 2, 18, 2], num_heads=[3, 6, 12, 24]),\n",
    "    'swin_base_224': dict(input_size=(224, 224), window_size=7, embed_dim=128, depths=[2, 2, 18, 2], num_heads=[4, 8, 16, 32]),\n",
    "    'swin_base_384': dict(input_size=(384, 384), window_size=12, embed_dim=128, depths=[2, 2, 18, 2], num_heads=[4, 8, 16, 32]),\n",
    "    'swin_large_224': dict(input_size=(224, 224), window_size=7, embed_dim=192, depths=[2, 2, 18, 2], num_heads=[6, 12, 24, 48]),\n",
    "    'swin_large_384': dict(input_size=(384, 384), window_size=12, embed_dim=192, depths=[2, 2, 18, 2], num_heads=[6, 12, 24, 48])\n",
    "}\n",
    "\n",
    "\n",
    "class Mlp(tf.keras.layers.Layer):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0., prefix=''):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = Dense(hidden_features, name=f'{prefix}/mlp/fc1')\n",
    "        self.fc2 = Dense(out_features, name=f'{prefix}/mlp/fc2')\n",
    "        self.drop = Dropout(drop)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = tf.keras.activations.gelu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    B, H, W, C = x.get_shape().as_list()\n",
    "    x = tf.reshape(x, shape=[-1, H // window_size,\n",
    "                   window_size, W // window_size, window_size, C])\n",
    "    x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n",
    "    windows = tf.reshape(x, shape=[-1, window_size, window_size, C])\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, H, W, C):\n",
    "    x = tf.reshape(windows, shape=[-1, H // window_size,\n",
    "                   W // window_size, window_size, window_size, C])\n",
    "    x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n",
    "    x = tf.reshape(x, shape=[-1, H, W, C])\n",
    "    return x\n",
    "\n",
    "\n",
    "class WindowAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0., prefix=''):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "        self.prefix = prefix\n",
    "\n",
    "        self.qkv = Dense(dim * 3, use_bias=qkv_bias,\n",
    "                         name=f'{self.prefix}/attn/qkv')\n",
    "        self.attn_drop = Dropout(attn_drop)\n",
    "        self.proj = Dense(dim, name=f'{self.prefix}/attn/proj')\n",
    "        self.proj_drop = Dropout(proj_drop)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.relative_position_bias_table = self.add_weight(f'{self.prefix}/attn/relative_position_bias_table',\n",
    "                                                            shape=(\n",
    "                                                                (2 * self.window_size[0] - 1) * (2 * self.window_size[1] - 1), self.num_heads),\n",
    "                                                            initializer=tf.initializers.Zeros(), trainable=True)\n",
    "\n",
    "        coords_h = np.arange(self.window_size[0])\n",
    "        coords_w = np.arange(self.window_size[1])\n",
    "        coords = np.stack(np.meshgrid(coords_h, coords_w, indexing='ij'))\n",
    "        coords_flatten = coords.reshape(2, -1)\n",
    "        relative_coords = coords_flatten[:, :,\n",
    "                                         None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.transpose([1, 2, 0])\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1).astype(np.int64)\n",
    "        self.relative_position_index = tf.Variable(initial_value=tf.convert_to_tensor(\n",
    "            relative_position_index), trainable=False, name=f'{self.prefix}/attn/relative_position_index')\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        B_, N, C = x.get_shape().as_list()\n",
    "        qkv = tf.transpose(tf.reshape(self.qkv(\n",
    "            x), shape=[-1, N, 3, self.num_heads, C // self.num_heads]), perm=[2, 0, 3, 1, 4])\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ tf.transpose(k, perm=[0, 1, 3, 2]))\n",
    "        relative_position_bias = tf.gather(self.relative_position_bias_table, tf.reshape(\n",
    "            self.relative_position_index, shape=[-1]))\n",
    "        relative_position_bias = tf.reshape(relative_position_bias, shape=[\n",
    "                                            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1])\n",
    "        relative_position_bias = tf.transpose(\n",
    "            relative_position_bias, perm=[2, 0, 1])\n",
    "        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.get_shape()[0]  # tf.shape(mask)[0]\n",
    "            attn = tf.reshape(attn, shape=[-1, nW, self.num_heads, N, N]) + tf.cast(\n",
    "                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32)\n",
    "            attn = tf.reshape(attn, shape=[-1, self.num_heads, N, N])\n",
    "            attn = tf.nn.softmax(attn, axis=-1)\n",
    "        else:\n",
    "            attn = tf.nn.softmax(attn, axis=-1)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = tf.transpose((attn @ v), perm=[0, 2, 1, 3])\n",
    "        x = tf.reshape(x, shape=[-1, N, C])\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def drop_path(inputs, drop_prob, is_training):\n",
    "    if (not is_training) or (drop_prob == 0.):\n",
    "        return inputs\n",
    "\n",
    "    # Compute keep_prob\n",
    "    keep_prob = 1.0 - drop_prob\n",
    "\n",
    "    # Compute drop_connect tensor\n",
    "    random_tensor = keep_prob\n",
    "    shape = (tf.shape(inputs)[0],) + (1,) * \\\n",
    "        (len(tf.shape(inputs)) - 1)\n",
    "    random_tensor += tf.random.uniform(shape, dtype=inputs.dtype)\n",
    "    binary_tensor = tf.floor(random_tensor)\n",
    "    output = tf.math.divide(inputs, keep_prob) * binary_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class DropPath(tf.keras.layers.Layer):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def call(self, x, training=None):\n",
    "        return drop_path(x, self.drop_prob, training)\n",
    "\n",
    "\n",
    "class SwinTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0, mlp_ratio=4.,\n",
    "                 qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path_prob=0., norm_layer=LayerNormalization, prefix=''):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "        self.prefix = prefix\n",
    "\n",
    "        self.norm1 = norm_layer(epsilon=1e-5, name=f'{self.prefix}/norm1')\n",
    "        self.attn = WindowAttention(dim, window_size=(self.window_size, self.window_size), num_heads=num_heads,\n",
    "                                    qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop, prefix=self.prefix)\n",
    "        self.drop_path = DropPath(\n",
    "            drop_path_prob if drop_path_prob > 0. else 0.)\n",
    "        self.norm2 = norm_layer(epsilon=1e-5, name=f'{self.prefix}/norm2')\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n",
    "                       drop=drop, prefix=self.prefix)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.shift_size > 0:\n",
    "            H, W = self.input_resolution\n",
    "            img_mask = np.zeros([1, H, W, 1])\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "            img_mask = tf.convert_to_tensor(img_mask)\n",
    "            mask_windows = window_partition(img_mask, self.window_size)\n",
    "            mask_windows = tf.reshape(\n",
    "                mask_windows, shape=[-1, self.window_size * self.window_size])\n",
    "            attn_mask = tf.expand_dims(\n",
    "                mask_windows, axis=1) - tf.expand_dims(mask_windows, axis=2)\n",
    "            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n",
    "            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n",
    "            self.attn_mask = tf.Variable(\n",
    "                initial_value=attn_mask, trainable=False, name=f'{self.prefix}/attn_mask')\n",
    "        else:\n",
    "            self.attn_mask = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.get_shape().as_list()\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = tf.reshape(x, shape=[-1, H, W, C])\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = tf.roll(\n",
    "                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2])\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = tf.reshape(\n",
    "            x_windows, shape=[-1, self.window_size * self.window_size, C])\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = tf.reshape(\n",
    "            attn_windows, shape=[-1, self.window_size, self.window_size, C])\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W, C)\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = tf.roll(shifted_x, shift=[\n",
    "                        self.shift_size, self.shift_size], axis=[1, 2])\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = tf.reshape(x, shape=[-1, H * W, C])\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchMerging(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_resolution, dim, norm_layer=LayerNormalization, prefix=''):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = Dense(2 * dim, use_bias=False,\n",
    "                               name=f'{prefix}/downsample/reduction')\n",
    "        self.norm = norm_layer(epsilon=1e-5, name=f'{prefix}/downsample/norm')\n",
    "\n",
    "    def call(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.get_shape().as_list()\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
    "\n",
    "        x = tf.reshape(x, shape=[-1, H, W, C])\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = tf.concat([x0, x1, x2, x3], axis=-1)\n",
    "        x = tf.reshape(x, shape=[-1, (H // 2) * (W // 2), 4 * C])\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path_prob=0., norm_layer=LayerNormalization, downsample=None, use_checkpoint=False, prefix=''):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = tf.keras.Sequential([SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                           num_heads=num_heads, window_size=window_size,\n",
    "                                           shift_size=0 if (\n",
    "                                               i % 2 == 0) else window_size // 2,\n",
    "                                           mlp_ratio=mlp_ratio,\n",
    "                                           qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                           drop=drop, attn_drop=attn_drop,\n",
    "                                           drop_path_prob=drop_path_prob[i] if isinstance(\n",
    "                                               drop_path_prob, list) else drop_path_prob,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           prefix=f'{prefix}/blocks{i}') for i in range(depth)])\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(\n",
    "                input_resolution, dim=dim, norm_layer=norm_layer, prefix=prefix)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.blocks(x)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchEmbed(tf.keras.layers.Layer):\n",
    "    def __init__(self, img_size=(224, 224), patch_size=(4, 4), in_chans=3, embed_dim=96, norm_layer=None):\n",
    "        super().__init__(name='patch_embed')\n",
    "        patches_resolution = [img_size[0] //\n",
    "                              patch_size[0], img_size[1] // patch_size[1]]\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = patches_resolution\n",
    "        self.num_patches = patches_resolution[0] * patches_resolution[1]\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.proj = Conv2D(embed_dim, kernel_size=patch_size,\n",
    "                           strides=patch_size, name='proj')\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(epsilon=1e-5, name='norm')\n",
    "        else:\n",
    "            self.norm = None\n",
    "\n",
    "    def call(self, x):\n",
    "        B, H, W, C = x.get_shape().as_list()\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x)\n",
    "        x = tf.reshape(\n",
    "            x, shape=[-1, (H // self.patch_size[0]) * (W // self.patch_size[0]), self.embed_dim])\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SwinTransformerModel(tf.keras.Model):\n",
    "    def __init__(self, model_name='swin_tiny_patch4_window7_224', include_top=False,\n",
    "                 img_size=(224, 224), patch_size=(4, 4), in_chans=3, num_classes=1000,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24],\n",
    "                 window_size=7, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=LayerNormalization, ape=False, patch_norm=True,\n",
    "                 use_checkpoint=False, **kwargs):\n",
    "        super().__init__(name=model_name)\n",
    "\n",
    "        self.include_top = include_top\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ape = ape\n",
    "        self.patch_norm = patch_norm\n",
    "        self.num_features = int(embed_dim * 2 ** (self.num_layers - 1))\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        # split image into non-overlapping patches\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer if self.patch_norm else None)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "\n",
    "        # absolute postion embedding\n",
    "        if self.ape:\n",
    "            self.absolute_pos_embed = self.add_weight('absolute_pos_embed',\n",
    "                                                      shape=(\n",
    "                                                          1, num_patches, embed_dim),\n",
    "                                                      initializer=tf.initializers.Zeros())\n",
    "\n",
    "        self.pos_drop = Dropout(drop_rate)\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x for x in np.linspace(0., drop_path_rate, sum(depths))]\n",
    "\n",
    "        # build layers\n",
    "        self.basic_layers = tf.keras.Sequential([BasicLayer(dim=int(embed_dim * 2 ** i_layer),\n",
    "                                                input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                                                  patches_resolution[1] // (2 ** i_layer)),\n",
    "                                                depth=depths[i_layer],\n",
    "                                                num_heads=num_heads[i_layer],\n",
    "                                                window_size=window_size,\n",
    "                                                mlp_ratio=self.mlp_ratio,\n",
    "                                                qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                                drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                                                drop_path_prob=dpr[sum(depths[:i_layer]):sum(\n",
    "                                                    depths[:i_layer + 1])],\n",
    "                                                norm_layer=norm_layer,\n",
    "                                                downsample=PatchMerging if (\n",
    "                                                    i_layer < self.num_layers - 1) else None,\n",
    "                                                use_checkpoint=use_checkpoint,\n",
    "                                                prefix=f'layers{i_layer}') for i_layer in range(self.num_layers)])\n",
    "        self.norm = norm_layer(epsilon=1e-5, name='norm')\n",
    "        self.avgpool = GlobalAveragePooling1D()\n",
    "        if self.include_top:\n",
    "            self.head = Dense(num_classes, name='head')\n",
    "        else:\n",
    "            self.head = None\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        x = self.basic_layers(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.avgpool(x)\n",
    "        return x\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        if self.include_top:\n",
    "            x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def SwinTransformer(model_name='swin_tiny_224', num_classes=1000, include_top=True, pretrained=True, use_tpu=False, cfgs=CFGS):\n",
    "    cfg = cfgs[model_name]\n",
    "    net = SwinTransformerModel(\n",
    "        model_name=model_name, include_top=include_top, num_classes=num_classes, img_size=cfg['input_size'], window_size=cfg[\n",
    "            'window_size'], embed_dim=cfg['embed_dim'], depths=cfg['depths'], num_heads=cfg['num_heads']\n",
    "    )\n",
    "    net(tf.keras.Input(shape=(cfg['input_size'][0], cfg['input_size'][1], 3)))\n",
    "    if pretrained is True:\n",
    "        url = f'https://github.com/rishigami/Swin-Transformer-TF/releases/download/v0.1-tf-swin-weights/{model_name}.tgz'\n",
    "        pretrained_ckpt = tf.keras.utils.get_file(\n",
    "            model_name, url, untar=True)\n",
    "    else:\n",
    "        pretrained_ckpt = pretrained\n",
    "\n",
    "    if pretrained_ckpt:\n",
    "        if tf.io.gfile.isdir(pretrained_ckpt):\n",
    "            pretrained_ckpt = f'{pretrained_ckpt}/{model_name}.ckpt'\n",
    "\n",
    "        if use_tpu:\n",
    "            load_locally = tf.saved_model.LoadOptions(\n",
    "                experimental_io_device='/job:localhost')\n",
    "            net.load_weights(pretrained_ckpt, options=load_locally)\n",
    "        else:\n",
    "            net.load_weights(pretrained_ckpt)\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:15.327090Z",
     "iopub.status.busy": "2021-11-12T10:38:15.325101Z",
     "iopub.status.idle": "2021-11-12T10:38:28.380843Z",
     "shell.execute_reply": "2021-11-12T10:38:28.380128Z",
     "shell.execute_reply.started": "2021-11-12T10:38:15.327047Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "img_size = 224\n",
    "NUM_CLASSES = 75\n",
    "\n",
    "base = SwinTransformer('swin_base_224', include_top=False, pretrained=True)\n",
    "base.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([layers.InputLayer(input_shape=(img_size, img_size,3)), \n",
    "                             layers.experimental.preprocessing.Resizing(224, 224),\n",
    "  tf.keras.layers.Lambda(lambda data: tf.keras.applications.imagenet_utils.preprocess_input(tf.cast(data, tf.float32), mode=\"torch\"), input_shape=[224, 224,3]),\n",
    "  base,\n",
    "  tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(NUM_CLASSES, activation= 'softmax'),\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:28.382535Z",
     "iopub.status.busy": "2021-11-12T10:38:28.382292Z",
     "iopub.status.idle": "2021-11-12T10:38:28.387355Z",
     "shell.execute_reply": "2021-11-12T10:38:28.386619Z",
     "shell.execute_reply.started": "2021-11-12T10:38:28.382502Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(\n",
    "      optimizer = tf.keras.optimizers.Adam(), \n",
    "      loss = 'sparse_categorical_crossentropy', \n",
    "      metrics=[\n",
    "      'accuracy',\n",
    "      tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name=\"top_5_accuracy\", dtype=None)\n",
    "      ]\n",
    ")\n",
    "#optimizers.Adam(),    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:28.389251Z",
     "iopub.status.busy": "2021-11-12T10:38:28.388735Z",
     "iopub.status.idle": "2021-11-12T10:38:28.411897Z",
     "shell.execute_reply": "2021-11-12T10:38:28.411298Z",
     "shell.execute_reply.started": "2021-11-12T10:38:28.389215Z"
    }
   },
   "outputs": [],
   "source": [
    "compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:38:28.413344Z",
     "iopub.status.busy": "2021-11-12T10:38:28.413081Z",
     "iopub.status.idle": "2021-11-12T13:12:27.338968Z",
     "shell.execute_reply": "2021-11-12T13:12:27.338255Z",
     "shell.execute_reply.started": "2021-11-12T10:38:28.413311Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    validation_data=valid_dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:14:24.499484Z",
     "iopub.status.busy": "2021-11-12T13:14:24.498734Z",
     "iopub.status.idle": "2021-11-12T13:14:24.810359Z",
     "shell.execute_reply": "2021-11-12T13:14:24.809604Z",
     "shell.execute_reply.started": "2021-11-12T13:14:24.499446Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summarizing the history for Accuracy\n",
    "metric = 'accuracy'\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(history.history[metric], 'g')\n",
    "plt.title(f'$Swin 224$ Categorical Accuracy')\n",
    "\n",
    "plt.ylabel(metric)\n",
    "plt.xlabel('epoch')\n",
    "if not os.path.exists('charts'):\n",
    "    os.makedirs('charts')\n",
    "\n",
    "plt.savefig(f\"charts/Categorical Accuracy.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:14:25.989267Z",
     "iopub.status.busy": "2021-11-12T13:14:25.988646Z",
     "iopub.status.idle": "2021-11-12T13:14:26.307886Z",
     "shell.execute_reply": "2021-11-12T13:14:26.307227Z",
     "shell.execute_reply.started": "2021-11-12T13:14:25.989219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summarizing the history for Loss\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(history.history['loss'], 'g')\n",
    "plt.title('$Swin 224$ Training Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "if not os.path.exists('charts'):\n",
    "    os.makedirs('charts')\n",
    "\n",
    "plt.savefig(\"charts/history_loss.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:14:27.483166Z",
     "iopub.status.busy": "2021-11-12T13:14:27.482911Z",
     "iopub.status.idle": "2021-11-12T13:14:27.489109Z",
     "shell.execute_reply": "2021-11-12T13:14:27.488054Z",
     "shell.execute_reply.started": "2021-11-12T13:14:27.483136Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.data.ops import dataset_ops\n",
    "from tensorflow.python.keras.layers.preprocessing import image_preprocessing\n",
    "from tensorflow.python.keras.preprocessing import dataset_utils\n",
    "from tensorflow.python.ops import image_ops\n",
    "from tensorflow.python.ops import io_ops\n",
    "from tensorflow.python.util.tf_export import keras_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:14:28.569254Z",
     "iopub.status.busy": "2021-11-12T13:14:28.568729Z",
     "iopub.status.idle": "2021-11-12T13:14:28.579558Z",
     "shell.execute_reply": "2021-11-12T13:14:28.578792Z",
     "shell.execute_reply.started": "2021-11-12T13:14:28.569210Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_mapping():\n",
    "    import pandas as pd\n",
    "    mapper = pd.DataFrame()\n",
    "    mapper['range']=[str(x) for x in range(75)]\n",
    "    mapper.sort_values(by='range',inplace=True)\n",
    "    mapper.reset_index(drop=True,inplace=True)\n",
    "    mapper.reset_index(inplace=True)\n",
    "    mapping_dict = {k:int(v) for k,v in zip(mapper['index'],mapper['range'])}\n",
    "    return mapping_dict\n",
    "\n",
    "mapping_dict = create_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:14:29.142120Z",
     "iopub.status.busy": "2021-11-12T13:14:29.141618Z",
     "iopub.status.idle": "2021-11-12T13:14:29.145496Z",
     "shell.execute_reply": "2021-11-12T13:14:29.144544Z",
     "shell.execute_reply.started": "2021-11-12T13:14:29.142082Z"
    }
   },
   "outputs": [],
   "source": [
    "#pred_val = model.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:14:30.069835Z",
     "iopub.status.busy": "2021-11-12T13:14:30.069292Z",
     "iopub.status.idle": "2021-11-12T13:15:19.817727Z",
     "shell.execute_reply": "2021-11-12T13:15:19.816971Z",
     "shell.execute_reply.started": "2021-11-12T13:14:30.069798Z"
    }
   },
   "outputs": [],
   "source": [
    "test = tf.keras.utils.image_dataset_from_directory('../input/food-places-test-224x224/processed_test',\n",
    "                                                   labels=None,image_size=(224,224),shuffle=False)\n",
    "pred_test = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:15:19.821834Z",
     "iopub.status.busy": "2021-11-12T13:15:19.821280Z",
     "iopub.status.idle": "2021-11-12T13:15:19.867118Z",
     "shell.execute_reply": "2021-11-12T13:15:19.866422Z",
     "shell.execute_reply.started": "2021-11-12T13:15:19.821803Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['Id'] = [int(x.replace('../input/food-places-test-224x224/processed_test/','').replace('.jpg','')) for x in test.file_paths]\n",
    "top_5 = pred_test.argsort(axis=-1)[:,-5:]\n",
    "test_df[[5-i for i in range(5)]] = top_5\n",
    "for i in range(1,6):\n",
    "    test_df[i] = [mapping_dict[x] for x in test_df[i]]\n",
    "test_df.sort_values(by='Id',inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)\n",
    "test_df\n",
    "test_df = test_df[['Id',1,2,3,4,5]]\n",
    "test_df.columns = ['Id','Top 1','Top 2','Top 3','Top 4','Top 5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:15:19.869035Z",
     "iopub.status.busy": "2021-11-12T13:15:19.868266Z",
     "iopub.status.idle": "2021-11-12T13:15:19.883132Z",
     "shell.execute_reply": "2021-11-12T13:15:19.882514Z",
     "shell.execute_reply.started": "2021-11-12T13:15:19.868993Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df[['Id','Top 1']].to_csv('submission_kaggle.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elearn Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:26:03.453733Z",
     "iopub.status.busy": "2021-11-12T13:26:03.453119Z",
     "iopub.status.idle": "2021-11-12T13:26:58.223545Z",
     "shell.execute_reply": "2021-11-12T13:26:58.222759Z",
     "shell.execute_reply.started": "2021-11-12T13:26:03.453692Z"
    }
   },
   "outputs": [],
   "source": [
    "test = tf.keras.utils.image_dataset_from_directory('../input/food-places-test-224x224/processed_test',\n",
    "                                                   labels=None,image_size=(224,224),shuffle=False)\n",
    "pred_test = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:22:40.167094Z",
     "iopub.status.busy": "2021-11-12T13:22:40.166678Z",
     "iopub.status.idle": "2021-11-12T13:22:40.177937Z",
     "shell.execute_reply": "2021-11-12T13:22:40.177188Z",
     "shell.execute_reply.started": "2021-11-12T13:22:40.167063Z"
    }
   },
   "outputs": [],
   "source": [
    "#for x in test.file_paths:\n",
    "    #print(x)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([int(x.replace('../input/food-places-test-224x224/processed_test/','').replace('.jpg','')) for x in test.file_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T13:23:04.405047Z",
     "iopub.status.busy": "2021-11-12T13:23:04.404713Z",
     "iopub.status.idle": "2021-11-12T13:23:04.748798Z",
     "shell.execute_reply": "2021-11-12T13:23:04.748075Z",
     "shell.execute_reply.started": "2021-11-12T13:23:04.405008Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df['Id'] = [int(x.replace('../input/food-places-test-224x224/processed_test/','').replace('.jpg','')) for x in test.file_paths]\n",
    "top_5 = pred_test.argsort(axis=-1)[:,-5:]\n",
    "test_df[[5-i for i in range(5)]] = top_5\n",
    "for i in range(1,6):\n",
    "    test_df[i] = [mapping_dict[x] for x in test_df[i]]\n",
    "test_df.sort_values(by='Id',inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)\n",
    "test_df\n",
    "test_df = test_df[['Id',1,2,3,4,5]]\n",
    "test_df.columns = ['Id','Top 1','Top 2','Top 3','Top 4','Top 5']\n",
    "test_df['Top 5'] = test_df[test_df.columns[1:]].apply(lambda x: ','.join(x.astype(str)),axis=1)\n",
    "test_df[['Id','Top 1','Top 5']].to_csv('submission_elearn.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
